---
{"dg-publish":true,"permalink":"/v2//aws/","noteIcon":""}
---



1. 왜 aws인가.
2. aws의 설정
3. ci/cd
4. 트러블슈팅
5. 후에 처리할 행동


# 왜 aws로 배포를 하였는가.

우리가 로컬 환경에서 개발한 웹사이트를 모든 사람이 접근할 수 있도록 하려면 적절한 호스팅 서비스가 필요합니다. 

그렇기에 우리 팀은 호스팅 서비스인 Vercel과 AWS 중에서 선택을 고민했습니다. Vercel은 빠르고 간편한 호스팅 서비스를 제공하지만, AWS에 비해 확장성이 다소 제한적입니다. 또한, Vercel도 결국 AWS 인프라 위에서 운영되는 서비스라는 점을 고려했습니다.

실제로 대규모 트래픽을 처리해야 하는 웹사이트를 개발하게 될 경우, 비용 효율성을 높이기 위해서는 AWS를 직접 활용하는 방법을 익히는 것이 중요하다고 판단했습니다.

이에 따라 저는 AWS를 이용한 배포 과정에서 구축한 CI/CD 환경, 웹 서버 설정, 그리고 발생했던 주요 트러블슈팅 사례들에 대해 설명하고자 합니다.


# aws의 기초 설정

우리는 Next.js를 사용하여 웹사이트를 개발할 예정입니다. 이에 따라 크게 두 가지 배포 방식을 고려했습니다:

1. EC2를 사용하여 가상 서버를 구축하는 방법
2. CloudFront, S3, 그리고 Lambda를 조합하여 서버리스 아키텍처로 SSR(Server-Side Rendering)을 구현하는 방법

두 번째 옵션(서버리스)도 고려했지만, 첫 번째 옵션인 EC2를 선택했습니다. 그 이유는 EC2가 서버에 대한 더 세밀한 설정과 높은 확장성을 제공한다고 판단했기 때문입니다.\


- 사용한 서비스들
![Pasted image 20241017113514.png](/img/user/%EC%9C%A0%ED%8B%B8%EB%A6%AC%ED%8B%B0/%EA%B0%9C%EB%B0%9C%EC%9E%90%EB%A3%8C%EC%82%AC%EC%A7%84/%EA%B0%9C%EB%B0%9C%EC%9E%90%EB%A3%8C%EC%82%AC%EC%A7%84/Pasted%20image%2020241017113514.png)

먼저 ec2의 설정부터 이야기해보자면

## 운영 체제 선택

Ubuntu 
- 많은 사람들이 사용하는 만큼 안정적이고 신뢰할수있는 os이기 때문 다양한 레퍼런스들이 많아서 접근하기 비교적 쉬웠기에 우분투 서버를 선택하였습니다.

## 인스턴스 설정

- 인스턴스 유형: t2.micro (프리티어)
- 키 페어: PEM
- 보안 그룹 설정: 
  인바운드 설정
  - 8080 (어플리케이션 서버)
  - 80 (HTTP)
  - 443 (HTTPS)
  - 22 (SSH)
- 스토리지 구성: 데이터 저장소로 사용

## 서버 접근 및 초기 설정
1. SSH로 서버 접근:
   ```
   ssh -i [키 파일 경로] [사용자명]@[퍼블릭 IP]
   ```
2. 기본 소프트웨어 설치:
   - Node.js
   - npm
   - git clone

이렇게 인스턴스를 생성하고 SSH 연결을 통해 가상 서버에 접근하여 기초적인 세팅을 해주었습니다.

추가 설정에 대해 적어보면

- 웹 서버 소프트웨어인 `nginx`를 설치하고 로드밸런싱을 위한 리버스 프록시, 포트포워딩 , 리다이렉팅 설정을 해주었습니다.
- `certbot`을 이용해서 `ssl` 인증서를 발급하고 https를 사용할수있는 상태로 변경해주었습니다.
- `CloudWatch`를 활용하여 인스턴스의 상태를 감시하고 특정 조건이 감지 될 경우 서버에 특정 행동을 하는 ( 서버에 많은 요청이나 과부하가 걸렸을때 자동으로 서버가 재시작 될수있게 ) 로직을 추가하였습니다
- `Route53`을 이용하여 도메인과 쉽게 연결하고 DNS 설정을 쉽게할수있었습니다.
- `IAM` 설정을 통해 다른 사용자가 AWS설정에 접근할수있게 사용자계정관리 설정을 해두었습니다.
- `PM2`를 통해 Next.js 서버를 24시간 백그라운드로 돌리고 무중단 서버의 관리를 쉽게할수있는 상황으로 만들어뒀습니다.

# CI/CD

## AWS CodePipeline vs GitHub Actions

AWS에 배포하고 관련 서비스를 사용하다 보면 CI/CD와 관련된 서비스도 지원함을 알 수 있습니다. AWS CodePipeline은 AWS 인프라에 쉽게 배포할 수 있고 시각적인 UI를 제공합니다.

하지만 AWS CodePipeline은 AWS 생태계에 종속되고 사용량에 따른 비용이 발생할 수 있다는 단점이 있습니다.

반면 GitHub Actions는 GitHub를 저장소로 사용한다면 쉽게 접근할 수 있습니다. 저장소와 원활하게 통합되며, 다양한 참고 자료가 있고 학습 곡선이 CodePipeline보다 낮습니다. 또한 공개 레포지토리라면 무료로 사용할 수 있어, 이를 활용하여 CI/CD 환경을 구축했습니다.

![1_hdpY0xvvuWXbd1llahp3Tw.webp](/img/user/%EC%9C%A0%ED%8B%B8%EB%A6%AC%ED%8B%B0/%EA%B0%9C%EB%B0%9C%EC%9E%90%EB%A3%8C%EC%82%AC%EC%A7%84/%EA%B0%9C%EB%B0%9C%EC%9E%90%EB%A3%8C%EC%82%AC%EC%A7%84/1_hdpY0xvvuWXbd1llahp3Tw.webp)


# CI/CD YAML 파일 구성

YAML 파일은 최종적으로 3개로 구성했습니다:

1. push나 pull request 후 `yarn build`를 실행하여 정상적으로 빌드되는지 확인하는 파일
2. 버전이 올라갈 때 Sentry에 새로운 소스맵을 업로드하고 릴리스를 생성하여 버전별 오류 추적을 용이하게 하는 파일
3. main 브랜치로 push 됐을 때 SSH 연결로 접근하여 파일을 가져오는 파일

이렇게 구축하여 빌드 테스트, 오류 추적, 배포 관련 자동화 작업을 수행할 수 있게 했습니다.

3번 YAML 파일은 main으로 push 됐을 때 22번 포트를 사용하여 Ubuntu 서버에 접근, 지정된 git 주소로 `git pull origin main` 명령어를 실행 후 `yarn`, `yarn build` 과정을 거치고 `pm2` 명령어를 통해 8080 포트로 서버를 실행시키는 구조로 만들었습니다.

# 트러블슈팅

## 1. build 시 인스턴스 다운 문제

위 과정에서 `git pull`까지는 정상 작동했지만, `yarn build` 이후 빌드 과정이 중단되는 문제가 발생했습니다.

```
  ▲ Next.js 14.2.8
  - Environments: .env
  - Experiments (use with caution):
    · instrumentationHook

   Creating an optimized production build ...
```

콘솔창에 딱 여기까지만 뜨고 더 이상 진행이 되지않는 이슈 발견

-> CloudWatch 확인 결과 CPU 사용률이 100%에 도달하며 인스턴스가 다운되는 상황이 발생했습니다.

해당 이슈에 대한 정보를 찾다가 원인을 메모리 부족으로 판단하고, 해결 방안으로 swap memory 설정을 시도했습니다.

```
스왑 메모리란, 실제 메모리 Ram이 가득 찼지만 더 많은 메모리가 필요할때 
디스코 공간을 이용하여 부족한 메모리를 대체할 수 있는 공간을 의미.
```

SSH를 통해 서버에 접속하여 swap memory 설정을 구현했습니다. 이 조치로 인스턴스 다운 문제는 해결되었으나, JavaScript 힙 메모리 부족으로 인한 빌드 실패 문제가 여전히 존재했습니다.

```exe
<--- JS stacktrace --->

FATAL ERROR: Reached heap limit Allocation failed - JavaScript heap out of memory
----- Native stack trace -----
```

메모리 관리에 대한 추가 조사 결과, 사용 가능한 메모리가 부족해질 경우 시스템은 swap 공간을 활용하여 메모리 사용을 분산시키지만, Node.js 빌드 프로세스에서 사용하는 V8 엔진의 메모리 할당에는 제한이 있다는 점을 발견했습니다. 기본적으로 Node.js는 최대 512MB의 힙 메모리 제한을 가지고 있습니다.

이 제한을 극복하기 위해 `export NODE_OPTIONS="--max-old-space-size=1024"` 명령어를 실행하여 Node.js의 최대 힙 메모리 크기를 1GB로 확장하기로 결정했습니다. 이 방법은 빌드 프로세스에 더 많은 메모리를 할당함으로써 메모리 부족 문제를 해결할 수 있을 것으로 기대했습니다.

그렇지만 여전히 뜨는 경고문과 Cloudwatch에서 사용된 메모리사용량 등을 종합해봤을때
평상시에는 정상적으로 메모리 가용량이 20퍼 밖에 안되지만 빌드시에만 과부하가 걸려 인스턴스가 다운된다는 점을 알게 되었습니다

여기서 문득든 생각이 그렇다면 메모리가 부족하니까 인스턴스의 스펙을 올리면 되는게 아닐까? 라고생각했었는데 현재 상황상 빌드때만 메모리가 부족한거지 평상시에는 메모리가 부족하지 않았고 더군다나 작은 프로젝트에서 값비싼 인스턴스를 구매해 사용하는것은 쉽게 말하는 돈낭비라고 생각했습니다. 
그렇게 때문에 저는 강사님과 멘토님을 찾아가 해당 이슈에 대한 설명을 해드리고 조언을 받았었습니다.

첫째, 강사님께서는 현재 사용 중인 AWS EC2 t2.micro 인스턴스(vCPU 1개, 메모리 1GB)의 한계를 지적하시며, 애플리케이션의 성능 병목이 메모리 부족에서 기인할 수 있다고 조언하셨습니다. 따라서, 상위 사양의 인스턴스로의 업그레이드를 통해 리소스 제약 문제를 해결할 수 있을 것이라 제안하셨습니다.

둘째, 멘토님께서는 이 문제가 생각보다 인터넷에 많은 사람들이 해당 이슈를 겪었다 라며 문제에 대한 여러 해결 방안을 제시해 주셨습니다. 하지만 그마저 이미 해본 swap memory나 node의 메모리 사용량 증가나 상위 사양의 인스턴스로 업그레이드였습니다.

그리고 제가 문제를 해결하기위한 힌트로 멘토님의 회사에서 실제 운용 중인 자동화된 CI/CD 파이프라인의 구조를 듣게 되었습니다. 이 구조는 다음과 같은 흐름으로 구성되어 있습니다:

1. 개발자의 메인 브랜치 코드 푸시
2. GitHub Actions를 활용한 자동화된 빌드 프로세스
3. Docker를 이용한 애플리케이션 컨테이너화
4. 컨테이너 이미지의 레지스트리 저장
5. EC2 인스턴스에서의 자동화된 이미지 풀 및 서비스 배포

Vercel과 GitHub Actions의 운영 메커니즘을 조사하면서, 두 플랫폼 모두 가상화된 Ubuntu 환경에서 워크플로우를 실행한다는 점을 확인했습니다. 이러한 인사이트를 바탕으로, 다음과 같은 최적화된 배포 전략을 구상하게 되었습니다:

- GitHub Action의 가상 Ubuntu 서버에서 애플리케이션 빌드 수행
- Linux 커맨드를 활용한 빌드 파일 압축
- SSH 프로토콜(포트 22)을 통한 EC2 인스턴스 접근
- Secure Copy Protocol(SCP)을 이용한 압축 파일 전송,해제 및 실행

이러한 접근 방식은 도커를 사용하지않고 하기 때문에 이러한 장단점들이 있었습니다. 

- 기술 스택 복잡성 감소로 인한 진입 장벽 완화
- 컨테이너 런타임 부재로 인한 서버 리소스 활용 최적화

- 개발, 테스트, 프로덕션 환경 간 일관성 유지의 어려움
- 다중 서버 환경에서의 동일 구성 복제 및 관리의 복잡성

그리고 마지막으로 필요없는 파일들을 쳐내고 서버가 돌아가는데 있어서 필요한 파일들만 보내게 변경하였고 

![Pasted image 20240927120128.png](/img/user/%EC%9C%A0%ED%8B%B8%EB%A6%AC%ED%8B%B0/%EA%B0%9C%EB%B0%9C%EC%9E%90%EB%A3%8C%EC%82%AC%EC%A7%84/%EA%B0%9C%EB%B0%9C%EC%9E%90%EB%A3%8C%EC%82%AC%EC%A7%84/Pasted%20image%2020240927120128.png)
![Pasted image 20241017141116.png](/img/user/%EC%9C%A0%ED%8B%B8%EB%A6%AC%ED%8B%B0/%EA%B0%9C%EB%B0%9C%EC%9E%90%EB%A3%8C%EC%82%AC%EC%A7%84/%EA%B0%9C%EB%B0%9C%EC%9E%90%EB%A3%8C%EC%82%AC%EC%A7%84/Pasted%20image%2020241017141116.png)

해당 이슈를 무사히 잘 고칠수있게 되었습니다.

느낀점 : 돈 아끼기 성공.

# 2. 프로덕션 환경에서 환경변수 설정과 이미지 파일이 정상적으로 작동 되지않던 이슈

(해당 자료는 발표용은 아닌거같고 그냥 한번 있었던 이슈 끄적여놓은겁니다.)

첫번째로 환경변수의 주입과 관한 문제입니다.

AWS에서 환경변수 주입에 필요한 서비스를 제공을 해주고 리눅스명령어를 통해서도 환경 변수를 주입 을 할 수 있는데 왠지 모르지만 적용이 안되는 이슈가 발생했습니다.

그렇기 때문에 다른 방법을 구상하다가 github secret key값에 환경변수들을 넣어두고 깃헙액션에서 빌드된 파일에 :env 를 통해 환경 변수를 주입할수있다는것을 알게되었고 이걸 통해서 빌드시 환경변수를 주입할수있게 문제를 해결했습니다.

두번째로는 로컬에 갖고 있을 이미지 파일이 정상적으로 출력되지 않는 문제입니다.

지금 워크플로우가

- GitHub Action의 가상 Ubuntu 서버에서 애플리케이션 빌드 수행
- Linux 커맨드를 활용한 빌드 파일 압축
- SSH 프로토콜(포트 22)을 통한 EC2 인스턴스 접근
- Secure Copy Protocol(SCP)을 이용한 압축 파일 전송,해제 및 실행

이런식으로 진행이 되고있었는데 이 압축파일을 최소한으로 보내다보니 용량이 큰 이미지파일이나 다른 파일들을 제외하고 .next 즉 빌드 결과물만 가상서버로 보냈었습니다. 

찾아보니 번들링되어 있는 .next파일에는 이미지 파일과 다른 config파일들은 이 빌드 결과물에 들어가지않는다는 점을 알게 되어

/front 파일에 변경점이 있을시 git pull origin main 명령어를 통해 새로 추가된 이미지 파일 , 설정 파일들을 가져올 수 있게 워크플로우를 추가하여 해결했습니다.

프로덕션 환경을 직접 컨트롤 하는 에러를 겪고 가상 서버에서의 환경과 로컬의 환경을 동일시하게 작업하는것도 하나의 기술인걸 알게 됐고 개발에는 다양한 방식이 있지만 언제나 베스트 프랙티스를 찾기 위해 사고를 전환해보는것도 많은 도움이 된거같습니다.

# 후에 처리할 행동

현재 자동화 플로우도 더 이상 수정할것도 없고 서버의 보안 때문에 경보기능(특정 조건이 됐을때 미리 설정해둔 행동을 실행하는 클라우드워치 기능)도 정상적으로 잘 돌아가고 있어 더 추가할건없고
docker를 추가하여 실제 배포환경과 개발환경의 상태를 동일시하게 하여 조금 더 좋은 인프라를 구성해보는것도 좋은 방법일거같습니다.